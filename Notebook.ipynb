{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_tlZ3i7w3ud",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import gc\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Reshape, concatenate, Concatenate, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard,LearningRateScheduler\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, jaccard_score\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.optimizers import AdamW\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from load_data import load_data\n",
        "from Evaluation_Metrics import metrics as m\n",
        "from Augmentation import augment\n",
        "from Train import train\n",
        "from Model import deeplabv1, deeplabv3, doubleunet, unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTx39qbgVVit"
      },
      "outputs": [],
      "source": [
        "img_size = 352\n",
        "X, Y = load_data(img_size, img_size, -1) #Resize (352,352) for Kvasir-SEG & CVC-ColonDB while (256,256) for CVC-ClinicDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sosaSqupU6qQ"
      },
      "outputs": [],
      "source": [
        "test_size = 0.2\n",
        "validation_size = 0.5\n",
        "\n",
        "#Split the the data into train:validation:test with 8:1:1 Ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=validation_size, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efSwj3xnVViv"
      },
      "source": [
        "# Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#If Output is float32 use dice_coeff2 and IoU2 else use dice_coeff and IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g3wjYeM8VViv"
      },
      "outputs": [],
      "source": [
        "epoch = 600\n",
        "lr = 0.0001\n",
        "dataset_type=\"\"\n",
        "model_type = \"\"\n",
        "model_path_1 = '' + dataset_type + '_' + model_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFob2psXVViv"
      },
      "outputs": [],
      "source": [
        "#Compile DeepLabV3 Model\n",
        "model_type_1 = deeplabv3.DeepLabV3(modelType=\"ResNet101\",shape=(352,352,3))\n",
        "optimizer = AdamW(learning_rate = lr, weight_decay = 0.004)\n",
        "loss = 'binary_crossentropy'\n",
        "model_type_1.compile(optimizer=optimizer, loss=loss,\n",
        "                     metrics=['accuracy',m.f1_score,m.dice_coeff2, m.dice_loss, m.total_loss, m.IoU, m.zero_IoU, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtZW5J1jVViv",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train.train_model(model=model_type_1, EPOCHS=epoch, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, learning_rate=lr, model_path=model_path_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-pFV8cIVViw"
      },
      "outputs": [],
      "source": [
        "model_type = \"\"\n",
        "model_path_2 = '' + dataset_type + '_' + model_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgRHifxVVViw"
      },
      "outputs": [],
      "source": [
        "model_type_2 = doubleunet.double_unet(352,352,3)\n",
        "optimizer = AdamW(\n",
        "    learning_rate = 0.00001, weight_decay = 0.004)\n",
        "loss = 'binary_crossentropy'\n",
        "model_type_2.compile(optimizer=optimizer, loss=loss,\n",
        "                     metrics=['accuracy',m.f1_score2,m.dice_coeff, m.dice_loss, m.total_loss, m.IoU, m.zero_IoU, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61qcx9iKVViw",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train.train_model(model=model_type_2, EPOCHS=epoch, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, learning_rate=lr, model_path=model_path_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf9WKIPGVViw"
      },
      "source": [
        "# Evaluation for Layer 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URSQwUpiVViw"
      },
      "outputs": [],
      "source": [
        "print(\"Loading the models\")\n",
        "\n",
        "model_type_1 = tf.keras.models.load_model(model_path_1, \n",
        "                                          custom_objects={'f1_score': m.f1_score,\n",
        "    'dice_coeff': m.dice_coeff,\n",
        "    'dice_loss': m.dice_loss,\n",
        "    'total_loss': m.total_loss,\n",
        "    'IoU': m.IoU,\n",
        "    'zero_IoU': m.zero_IoU,\n",
        "    'dice_metric_loss': m.dice_metric_loss})\n",
        "model_type_1_preds_tr = model_type_1.predict(X_train, batch_size=4)\n",
        "model_type_1_preds_val = model_type_1.predict(X_val, batch_size=4)\n",
        "model_type_1_preds_t = model_type_1.predict(X_test, batch_size=4)\n",
        "\n",
        "model_type_2 = tf.keras.models.load_model(model_path_2, \n",
        "                                          custom_objects={'f1_score': m.f1_score2,\n",
        "    'dice_coeff': m.dice_coeff,\n",
        "    'dice_loss': m.dice_loss,\n",
        "    'total_loss': m.total_loss,\n",
        "    'IoU': m.IoU,\n",
        "    'zero_IoU': m.zero_IoU,\n",
        "    'dice_metric_loss': m.dice_metric_loss})\n",
        "model_type_2_preds_tr = model_type_2.predict(X_train, batch_size=4)\n",
        "model_type_2_preds_val = model_type_2.predict(X_val, batch_size=4)\n",
        "model_type_2_preds_t = model_type_2.predict(X_test, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xH5sO7nVViw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, jaccard_score\n",
        "\n",
        "ground_truth_flat = y_test.flatten()\n",
        "predictions_flat = np.round(model_type_1_preds_t).flatten()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(ground_truth_flat, predictions_flat)\n",
        "precision = precision_score(ground_truth_flat, predictions_flat)\n",
        "recall = recall_score(ground_truth_flat, predictions_flat)\n",
        "f1 = f1_score(ground_truth_flat, predictions_flat)\n",
        "jaccard = jaccard_score(ground_truth_flat, predictions_flat)\n",
        "\n",
        "# Print or log the evaluation metrics\n",
        "print(\"Model_Type_1: \")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"IoU: {jaccard}\")\n",
        "\n",
        "predictions_flat = np.round(model_type_2_preds_t).flatten()\n",
        "\n",
        "accuracy = accuracy_score(ground_truth_flat, predictions_flat)\n",
        "precision = precision_score(ground_truth_flat, predictions_flat)\n",
        "recall = recall_score(ground_truth_flat, predictions_flat)\n",
        "f1 = f1_score(ground_truth_flat, predictions_flat)\n",
        "jaccard = jaccard_score(ground_truth_flat, predictions_flat)\n",
        "\n",
        "# Print or log the evaluation metrics\n",
        "print(\"Model_Type_2: \")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"IoU: {jaccard}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yCD2zrLVVix"
      },
      "source": [
        "## New inputs for Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP9UdI2RVVix"
      },
      "outputs": [],
      "source": [
        "#Combine Model_type_1 and Model_type_2 Train predictions using averaging method and concatenate it with the training set.\n",
        "average_preds_tr = (model_type_1_preds_tr + model_type_2_preds_tr) / 2.0\n",
        "train_with_predictions = np.concatenate([X_train, average_preds_tr], axis=-1)\n",
        "\n",
        "#Combine Model_type_1 and Model_type_2 Validation Predictions using averaging method and concatenate it with the validation set.\n",
        "average_preds_val = (model_type_1_preds_val + model_type_2_preds_val) / 2.0\n",
        "val_with_predictions = np.concatenate([X_val, average_preds_val], axis=-1)\n",
        "\n",
        "#Combine Model_type_1 and Model_type_2 Predictions using averaging method and concatenate it with the validation set.\n",
        "average_preds_t = (model_type_1_preds_t + model_type_2_preds_t) / 2.0\n",
        "test_with_predictions = np.concatenate([X_test, average_preds_t], axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjfCHWWGVVix"
      },
      "source": [
        "# Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBn9Ga5_VVix"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "lr2 = 0.00001\n",
        "log_dir = './logs/fit' + datetime.now().strftime('%d.%m.%Y--%H-%M-%S')\n",
        "model_path_3 = ''\n",
        "checkpoint = ModelCheckpoint(model_path_3, monitor='val_dice_metric_loss', verbose = 1, save_best_only=True,\n",
        "                            mode='min', save_freq='epoch')\n",
        "early = EarlyStopping(monitor='val_dice_metric_loss', min_delta=0, patience = 25, verbose = 1, mode='min')\n",
        "board = TensorBoard(log_dir=log_dir,histogram_freq = 1)\n",
        "tensorboard_callback = [checkpoint,early,board]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7QKOEAXVVix",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(learning_rate = lr2, weight_decay = 0.004)\n",
        "loss = 'binary_crossentropy'\n",
        "model_type_3 = unet.unet(input_shape=(352,352,4))\n",
        "model_type_3.compile(optimizer=optimizer, loss=loss, \n",
        "                    metrics=['accuracy',m.f1_score2,m.dice_metric_loss,m.dice_coeff,m.dice_loss, m.total_loss, m.IoU, m.zero_IoU, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_type_3.fit(train_with_predictions, y_train,\n",
        "                  batch_size=8,epochs=400,\n",
        "                  validation_data=(val_with_predictions, y_val),\n",
        "                  callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQj687EIVVi1"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "log_dir = './logs/fit' + datetime.now().strftime('%d.%m.%Y--%H-%M-%S')\n",
        "model_path_4 = ''\n",
        "checkpoint = ModelCheckpoint(model_path_4, monitor='val_dice_metric_loss', verbose = 1, save_best_only=True,\n",
        "                            mode='min', save_freq='epoch')\n",
        "early = EarlyStopping(monitor='val_dice_metric_loss', min_delta=0, patience = 25, verbose = 1, mode='min')\n",
        "board = TensorBoard(log_dir=log_dir,histogram_freq = 1)\n",
        "tensorboard_callback = [checkpoint,early,board]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqrSr_0OVVi1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(learning_rate = lr2, weight_decay = 0.004)\n",
        "loss = 'binary_crossentropy'\n",
        "model_type_4 = deeplabv1.deeplab(input_shape=(352,352,4))\n",
        "model_type_4.compile(optimizer=optimizer, loss=loss, \n",
        "                       metrics=['accuracy',m.f1_score2,m.dice_metric_loss,m.dice_coeff,m.dice_loss, m.total_loss, m.IoU, m.zero_IoU, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_type_4.fit(train_with_predictions, y_train,\n",
        "                  batch_size=8,epochs=400,\n",
        "                  validation_data=(val_with_predictions, y_val),\n",
        "                  callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNmF6kkzVVi1"
      },
      "source": [
        "## Layer 2 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwFI0H6-VVi1"
      },
      "outputs": [],
      "source": [
        "model_type_3 = tf.keras.models.load_model(model_path_3, \n",
        "                                          custom_objects={'f1_score': m.f1_score2,\n",
        "        'dice_coeff': m.dice_coeff,\n",
        "        'dice_loss': m.dice_loss,\n",
        "        'total_loss': m.total_loss,\n",
        "        'IoU': m.IoU,\n",
        "        'zero_IoU': m.zero_IoU,\n",
        "        'dice_metric_loss':m.dice_metric_loss})\n",
        "model_type_3_t = model_type_3.predict(test_with_predictions,batch_size=4)\n",
        "\n",
        "model_type_4 = tf.keras.models.load_model(model_path_4, \n",
        "                                          custom_objects={'f1_score': m.f1_score,\n",
        "        'dice_coeff': m.dice_coeff,\n",
        "        'dice_loss': m.dice_loss,\n",
        "        'total_loss': m.total_loss,\n",
        "        'IoU': m.IoU,\n",
        "        'zero_IoU': m.zero_IoU,\n",
        "        'dice_metric_loss':m.dice_metric_loss})\n",
        "model_type_4_t = model_type_4.predict(test_with_predictions,batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNRIDx3bVVi1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, jaccard_score\n",
        "\n",
        "ground_truth_flat = y_test.flatten()\n",
        "predictions_flat = np.round(model_type_3_t).flatten()\n",
        "\n",
        "accuracy = accuracy_score(ground_truth_flat, predictions_flat)\n",
        "precision = precision_score(ground_truth_flat, predictions_flat)\n",
        "recall = recall_score(ground_truth_flat, predictions_flat)\n",
        "f1 = f1_score(ground_truth_flat, predictions_flat)\n",
        "jaccard = jaccard_score(ground_truth_flat, predictions_flat)\n",
        "\n",
        "print(\"Model_Type_3: \")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"IoU: {jaccard}\")\n",
        "\n",
        "predictions_flat = np.round(model_type_4_t).flatten()\n",
        "\n",
        "accuracy = accuracy_score(ground_truth_flat, predictions_flat)\n",
        "precision = precision_score(ground_truth_flat, predictions_flat)\n",
        "recall = recall_score(ground_truth_flat, predictions_flat)\n",
        "f1 = f1_score(ground_truth_flat, predictions_flat)\n",
        "jaccard = jaccard_score(ground_truth_flat, predictions_flat)\n",
        "\n",
        "print(\"Model_Type_4: \")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"IoU: {jaccard}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRjoK7UjVVi1"
      },
      "source": [
        "# Final Output Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds7uddpLVVi1"
      },
      "outputs": [],
      "source": [
        "#Combine Model_Type_3 and Model_Type_4 preds by using the averaging method and we get the final prediction.\n",
        "average2_preds_test = (model_type_3_t + model_type_4_t) / 2.0\n",
        "average2_preds_t = np.round(average2_preds_test).flatten()\n",
        "y_test_flat = y_test.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UngUfjRPVVi1"
      },
      "outputs": [],
      "source": [
        "avg_ensemble_accuracy = accuracy_score(y_test_flat, average2_preds_t)\n",
        "avg_ensemble_f1 = f1_score(y_test_flat, average2_preds_t)\n",
        "avg_ensemble_precision = precision_score(y_test_flat, average2_preds_t)\n",
        "avg_ensemble_recall = recall_score(y_test_flat, average2_preds_t)\n",
        "avg_ensemble_iou = jaccard_score(y_test_flat, average2_preds_t)\n",
        "\n",
        "# Display ensemble metrics\n",
        "print(\"Averaged Ensemble Accuracy:\", avg_ensemble_accuracy)\n",
        "print(\"Averaged Ensemble F1 Score:\", avg_ensemble_f1)\n",
        "print(\"Averaged Ensemble Precision:\", avg_ensemble_precision)\n",
        "print(\"Averaged Ensemble Recall:\", avg_ensemble_recall)\n",
        "print(\"Averaged Ensemble IoU:\", avg_ensemble_iou)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC4Xxxq8VVi1"
      },
      "source": [
        "# Visualization of Models from layer 1, layer 2, and final output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Pyb4msDbZMR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "num_samples_to_visualize = 20\n",
        "random_indices = np.random.choice(range(len(X_test)), num_samples_to_visualize, replace=False)\n",
        "\n",
        "# Visualize each selected sample\n",
        "for sample_index in random_indices:\n",
        "    # Load the original image and corresponding mask\n",
        "    original_image = X_test[sample_index]\n",
        "    actual_mask = y_test[sample_index]\n",
        "\n",
        "    # Get predictions for the chosen sample\n",
        "    doubleunet_prediction = np.round(model_type_1_preds_t[sample_index, ..., 0])\n",
        "    deeplabv3p_prediction = np.round(model_type_2_preds_t[sample_index, ..., 0])\n",
        "    avg_prediction = np.round(average_preds_t[sample_index])\n",
        "    unet2_prediction = np.round(model_type_3_t[sample_index, ..., 0])\n",
        "    deeplab2_prediction = np.round(model_type_4_t[sample_index, ..., 0])\n",
        "    avg2_prediction = np.round(average2_preds_test[sample_index])\n",
        "    # Plot the images and predictions\n",
        "    plt.figure(figsize=(20, 20))\n",
        "\n",
        "    plt.subplot(1, 11, 1)\n",
        "    plt.imshow(original_image)\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 11, 2)\n",
        "    plt.imshow(original_image[:, :, 0], cmap='Reds')\n",
        "    plt.title(\"Red Channel\")\n",
        "\n",
        "    plt.subplot(1, 11, 3)\n",
        "    plt.imshow(original_image[:, :, 1], cmap='Greens')\n",
        "    plt.title(\"Green Channel\")\n",
        "\n",
        "    plt.subplot(1, 11, 4)\n",
        "    plt.imshow(original_image[:, :, 2], cmap='Blues')\n",
        "    plt.title(\"Blue Channel\")\n",
        "\n",
        "    plt.subplot(1, 11, 5)\n",
        "    plt.imshow(actual_mask, cmap='gray')\n",
        "    plt.title(\"Actual Mask\")\n",
        "\n",
        "    plt.subplot(1, 11, 6)\n",
        "    plt.imshow(doubleunet_prediction, cmap='gray')\n",
        "    plt.title(\"DoubleU-Net\")\n",
        "\n",
        "    plt.subplot(1, 11, 7)\n",
        "    plt.imshow(deeplabv3p_prediction, cmap='gray')\n",
        "    plt.title(\"Deeplab V3 Plus\")\n",
        "\n",
        "    plt.subplot(1, 11, 8)\n",
        "    plt.imshow(avg_prediction, cmap='gray')\n",
        "    plt.title(\"Avg Layer 1\")\n",
        "\n",
        "    plt.subplot(1, 11, 9)\n",
        "    plt.imshow(unet2_prediction, cmap='gray')\n",
        "    plt.title(\"U-Net 2\")\n",
        "\n",
        "    plt.subplot(1, 11, 10)\n",
        "    plt.imshow(deeplab2_prediction, cmap='gray')\n",
        "    plt.title(\"Deeplab 2\")\n",
        "\n",
        "    plt.subplot(1, 11, 11)\n",
        "    plt.imshow(avg2_prediction, cmap='gray')\n",
        "    plt.title(\"Avg Layer 2\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
